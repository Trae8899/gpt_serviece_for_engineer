import streamlit as st
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import OpenAI,ChatOpenAI
from langchain_openai import AzureOpenAI,AzureChatOpenAI
from langchain.llms.fake import FakeListLLM
from st_pages import Page, Section, show_pages, add_page_title, hide_pages
from streamlit_feedback import streamlit_feedback

st.set_page_config(page_title="RFP Search Bot", page_icon="ğŸ¦œ")
st.title("ğŸ¦œ RFP Search Bot")
st.sidebar.image(r"C:\Users\qkrwo\Documents\Digital\JPark\gpt_serviece_for_engineer\asset\Doosan_Logo.jpg")
st.sidebar.write("# EPC)PE CENTER ğŸ‘‹")

st.sidebar.success("Select a model that you want.")

if 'llms' not in st.session_state:
    st.session_state['llms'] = 'OPENAI'
if 'OPENAIAPI' not in st.session_state:
    st.session_state['OPENAIAPI'] = None
if 'AZURE_OPENAI_API_KEY' not in st.session_state:
    st.session_state['AZURE_OPENAI_API_KEY'] = None
if 'AZURE_OPENAI_ENDPOINT' not in st.session_state:
    st.session_state['AZURE_OPENAI_ENDPOINT'] = None

# ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë“ˆ ì„ íƒ
def update_llms():
    st.session_state['llms'] = st.session_state.selectllm

# ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë“ˆ ì„ íƒ
selectllm = st.sidebar.selectbox(
    "Which Module do you want?",
    ("OPENAI", "AZURE OPEN AI", "FAKELLM"),
    index=["OPENAI", "AZURE OPEN AI", "FAKELLM"].index(st.session_state['llms']),
    key='selectllm',
    on_change=update_llms
)

if st.session_state['llms'] == "OPENAI":
    st.session_state['OPENAIAPI'] = st.sidebar.text_input("API KEY", value=st.session_state['OPENAIAPI'],type="password")
    llm = ChatOpenAI(openai_api_key=st.session_state['OPENAIAPI'],model="gpt-4o")
    
elif st.session_state['llms'] == "AZURE OPEN AI":
    st.session_state['AZURE_OPENAI_API_KEY'] = st.sidebar.text_input("API KEY", value=st.session_state['AZURE_OPENAI_API_KEY'])
    st.session_state['AZURE_OPENAI_ENDPOINT'] = st.sidebar.text_input("END POINT", value=st.session_state['AZURE_OPENAI_ENDPOINT'])
    llm = AzureChatOpenAI()
else:
    llm=FakeListLLM(responses=["fakellm1","fakellm2","fakellm3"])


# LangChain ì„¤ì •
pjtname=st.selectbox(
    "PJT NAME",
    ("jawa9&10","lumar","samcheok"),
    )
# gpt-3.5-turbo-instruct
# llm = ChatOpenAI(openai_api_key=st.session_state['OPENAIAPI'],model="gpt-4o")
# llm = OpenAI(openai_api_key=st.session_state['OPENAIAPI'],model_name="gpt-4o")
memory = ConversationBufferMemory()
llm_chain = ConversationChain(llm=llm, memory=memory)



# ì±„íŒ… ê¸°ë¡ ìœ ì§€
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.feedback_scores = []

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
reset_history = st.sidebar.button("Reset chat history")
if reset_history:
    st.session_state.messages = []
    st.session_state.feedback_scores = []
    st.session_state.last_response = None

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for i, msg in enumerate(st.session_state.messages):
    st.chat_message(msg["role"]).write(msg["content"])
    if msg["role"] == "assistant":
        feedback = streamlit_feedback(
            feedback_type="faces",
            optional_text_label="[Optional] Please provide an explanation",
            key=f"feedback_{i}",
        )
        if feedback:
            scores = {"ğŸ˜€": 1, "ğŸ™‚": 0.75, "ğŸ˜": 0.5, "ğŸ™": 0.25, "ğŸ˜": 0}
            score = scores[feedback["score"]]
            st.session_state.feedback_scores.append({"index": i, "score": score, "comment": feedback.get("text", "")})
            if feedback.get("text"):
                st.write(f"Comment: {feedback['text']}")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if input := st.chat_input(placeholder="Ask me anything..."):
    st.session_state.messages.append({"role": "user", "content": input})
    st.chat_message("user").write(input)

    # LangChainì„ ì‚¬ìš©í•œ OpenAI API í˜¸ì¶œ
    response = llm_chain.run(input)
    
    # ì‘ë‹µ ì €ì¥ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "assistant", "content": response})
    st.chat_message("assistant").write(response)

    with st.expander("Show Original Lessons"):
        st.write("ì›ë³¸ retriever data ëª‡ê°œ")

# í”¼ë“œë°±ì„ ë°˜ì˜í•œ ë‹¤ìŒ ëŒ€í™” ì¡°ì •
def adjust_response_based_on_feedback(response, feedback_scores):
    if not feedback_scores:
        return response

    # ê°€ì¥ ìµœê·¼ì˜ í”¼ë“œë°±ì„ ì‚¬ìš©í•˜ì—¬ ì¡°ì •
    latest_feedback = feedback_scores[-1]
    score = latest_feedback["score"]
    
    if score < 0.5:
        return "I'm sorry if my previous responses were not helpful. How can I assist you better?"
    elif score < 0.75:
        return "I'll try to improve my responses. What else would you like to know?"
    else:
        return response

# ë§ˆì§€ë§‰ ì‘ë‹µì— ëŒ€í•œ í”¼ë“œë°±ì„ ë°˜ì˜í•œ í›„ì† ì§ˆë¬¸
if st.session_state.messages and st.session_state.feedback_scores:
    last_response = st.session_state.messages[-1]["content"]
    adjusted_response = adjust_response_based_on_feedback(last_response, st.session_state.feedback_scores)
    if adjusted_response != last_response:
        st.write(f"Adjusted response: {adjusted_response}")