import streamlit as st
import pandas as pd
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import OpenAI, ChatOpenAI
from langchain_openai import AzureOpenAI,AzureChatOpenAI
from langchain.llms.fake import FakeListLLM
from st_pages import Page, Section, show_pages, add_page_title, hide_pages
from streamlit_feedback import streamlit_feedback

st.set_page_config(
    page_title="LL_Search",
    page_icon="ğŸ‘‹",
)
st.title("ğŸ‘‹ LL_Search")

st.sidebar.image(r"C:\Users\qkrwo\Documents\Digital\JPark\gpt_serviece_for_engineer\asset\Doosan_Logo.jpg")
st.sidebar.write("# EPC)PE CENTER ğŸ‘‹")

st.sidebar.success("Select a model that you want.")

if 'llms' not in st.session_state:
    st.session_state['llms'] = 'OPENAI'
if 'OPENAIAPI' not in st.session_state:
    st.session_state['OPENAIAPI'] = None
if 'AZURE_OPENAI_API_KEY' not in st.session_state:
    st.session_state['AZURE_OPENAI_API_KEY'] = None
if 'AZURE_OPENAI_ENDPOINT' not in st.session_state:
    st.session_state['AZURE_OPENAI_ENDPOINT'] = None

# ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë“ˆ ì„ íƒ
def update_llms():
    st.session_state['llms'] = st.session_state.selectllm

# ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë“ˆ ì„ íƒ
selectllm = st.sidebar.selectbox(
    "Which Module do you want?",
    ("OPENAI", "AZURE OPEN AI", "FAKELLM"),
    index=["OPENAI", "AZURE OPEN AI", "FAKELLM"].index(st.session_state['llms']),
    key='selectllm',
    on_change=update_llms
)

if st.session_state['llms'] == "OPENAI":
    st.session_state['OPENAIAPI'] = st.sidebar.text_input("API KEY", value=st.session_state['OPENAIAPI'],type="password")
    llm = ChatOpenAI(openai_api_key=st.session_state['OPENAIAPI'],model="gpt-4o")
    
elif st.session_state['llms'] == "AZURE OPEN AI":
    st.session_state['AZURE_OPENAI_API_KEY'] = st.sidebar.text_input("API KEY", value=st.session_state['AZURE_OPENAI_API_KEY'])
    st.session_state['AZURE_OPENAI_ENDPOINT'] = st.sidebar.text_input("END POINT", value=st.session_state['AZURE_OPENAI_ENDPOINT'])
    llm = AzureChatOpenAI()
else:
    llm=FakeListLLM(responses=["fakellm1","fakellm2","fakellm3"])

# Read the Excel file with lessons and learnings
df = pd.read_excel(r'C:\Users\qkrwo\Documents\Digital\JPark\gpt_serviece_for_engineer\asset\ll_list\ll_list.xlsx')
lessons_list = df.to_dict(orient='records')

# LangChain ì„¤ì •
# llm = ChatOpenAI(openai_api_key=st.session_state['OPENAIAPI'], model="gpt-4o")
memory = ConversationBufferMemory()
llm_chain = ConversationChain(llm=llm, memory=memory)

# Function to include lessons and learnings in the conversation
def include_lessons_in_response(input_text, lessons_list):
    # Implement a simple search to find relevant lessons
    relevant_lessons = [lesson for lesson in lessons_list if any(word.lower() in input_text.lower() for word in lesson.values())]
    # lessons_text = "\n".join([f"Title: {lesson['Title (ì´ìŠˆì œëª©)']}\nIssue Details: {lesson['Issue_Details (ìƒì„¸ ë‚´ìš©)']}\nAction Result: {lesson['Action_Result (ì¡°ì¹˜ê²°ê³¼)']}\nCause: {lesson['Cause (ê·¼ë³¸ì›ì¸)']}\nPreventive Measures: {lesson['Preventive_measures (í–¥í›„ ê°œì„  ë°©í–¥)']}" for lesson in relevant_lessons])
    # print(relevant_lessons)
    # print(lessons_text)
    return relevant_lessons


# ì±„íŒ… ê¸°ë¡ ìœ ì§€
if "llmessage" not in st.session_state:
    st.session_state.llmessage = []
    st.session_state.llfeedback_scores = []

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
reset_history = st.sidebar.button("Reset chat history")
if reset_history:
    st.session_state.llmessage = []
    st.session_state.llfeedback_scores = []
    st.session_state.last_response = None

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for i, msg in enumerate(st.session_state.llmessage):
    st.chat_message(msg["role"]).write(msg["content"])
    if msg["role"] == "assistant":
        feedback = streamlit_feedback(
            feedback_type="faces",
            optional_text_label="[Optional] Please provide an explanation",
            key=f"feedback_{i}",
        )
        if feedback:
            scores = {"ğŸ˜€": 1, "ğŸ™‚": 0.75, "ğŸ˜": 0.5, "ğŸ™": 0.25, "ğŸ˜": 0}
            score = scores[feedback["score"]]
            st.session_state.llfeedback_scores.append({"index": i, "score": score, "comment": feedback.get("text", "")})
            if feedback.get("text"):
                st.write(f"Comment: {feedback['text']}")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if input := st.chat_input(placeholder="Ask me anything..."):
    st.session_state.llmessage.append({"role": "user", "content": input})
    st.chat_message("user").write(input)

    # Include lessons in the response
    lessons_text = include_lessons_in_response(input, lessons_list)

    modified_input = f"{input}\n\nRelated Lessons and Learnings:\n{lessons_text}"
    print(modified_input)

    # LangChainì„ ì‚¬ìš©í•œ OpenAI API í˜¸ì¶œ
    if len(lessons_text)>0:
        response = llm_chain.run(modified_input)
    else:
        response="ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    
    # ì‘ë‹µ ì €ì¥ ë° í‘œì‹œ
    st.session_state.llmessage.append({"role": "assistant", "content": response})
    st.chat_message("assistant").write(response)
    
    # í™•ì¥ ë²„íŠ¼ì„ í†µí•´ ì›ë³¸ lessons_text í‘œì‹œ
    with st.expander("Show Original Lessons"):
        st.write(st.dataframe(lessons_list))

# í”¼ë“œë°±ì„ ë°˜ì˜í•œ ë‹¤ìŒ ëŒ€í™” ì¡°ì •
def adjust_response_based_on_feedback(response, feedback_scores):
    if not feedback_scores:
        return response

    # ê°€ì¥ ìµœê·¼ì˜ í”¼ë“œë°±ì„ ì‚¬ìš©í•˜ì—¬ ì¡°ì •
    latest_feedback = feedback_scores[-1]
    score = latest_feedback["score"]
    
    if score < 0.5:
        return "I'm sorry if my previous responses were not helpful. How can I assist you better?"
    elif score < 0.75:
        return "I'll try to improve my responses. What else would you like to know?"
    else:
        return response

# ë§ˆì§€ë§‰ ì‘ë‹µì— ëŒ€í•œ í”¼ë“œë°±ì„ ë°˜ì˜í•œ í›„ì† ì§ˆë¬¸
if st.session_state.llmessage and st.session_state.llfeedback_scores:
    last_response = st.session_state.llmessage[-1]["content"]
    adjusted_response = adjust_response_based_on_feedback(last_response, st.session_state.llfeedback_scores)
    if adjusted_response != last_response:
        st.write(f"Adjusted response: {adjusted_response}")